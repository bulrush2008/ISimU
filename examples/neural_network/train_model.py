"""
ç¥ç»ç½‘ç»œè®­ç»ƒç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ„å»ºçš„ç¥ç»ç½‘ç»œæ¨¡å—è®­ç»ƒCFDä»£ç†æ¨¡å‹
"""

import sys
import os
import torch
import warnings
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
base_dir = Path(__file__).parent.parent.parent
src_dir = base_dir / 'src'
sys.path.insert(0, str(src_dir))

from neural_network import (
    CFDDataModule,
    create_trainer,
    create_model
)

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("=== ISimU ç¥ç»ç½‘ç»œè®­ç»ƒç¤ºä¾‹ ===\n")

    # é…ç½®å‚æ•°
    config = {
        # æ•°æ®é…ç½®
        'data_dir': str(base_dir / 'matrix_data'),
        'grid_size': (64, 64, 64),
        'batch_size': 1,  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
        'train_ratio': 0.8,
        'val_ratio': 0.1,
        'test_ratio': 0.1,

        # æ¨¡å‹é…ç½®
        'model_type': 'fc',  # 'fc', 'conv', 'hybrid'
        'model_kwargs': {
            'hidden_dims': [512, 1024, 2048, 1024, 512],  # å‡å°ç½‘ç»œè§„æ¨¡é€‚åº”å°æ•°æ®é›†
            'dropout_rate': 0.1,
            'use_batch_norm': True,
            'activation': 'relu'
        },

        # è®­ç»ƒé…ç½®
        'epochs': 100,  # å¿«é€Ÿæµ‹è¯•ï¼Œå®é™…è®­ç»ƒå¯ä»¥å¢åŠ åˆ°1000+
        'learning_rate': 1e-4,
        'weight_decay': 1e-5,
        'optimizer': 'Adam',
        'scheduler': 'cosine',
        'early_stopping_patience': 20,  # å‡å°patienceç”¨äºå¿«é€Ÿæµ‹è¯•

        # æŸå¤±å‡½æ•°é…ç½®
        'loss_function': 'combined',
        'loss_kwargs': {
            'mse_weight': 1.0,
            'physics_weight': 0.05,  # é™ä½ç‰©ç†çº¦æŸæƒé‡
            'inside_weight': 1.0,
            'outside_weight': 0.1
        },

        # å…¶ä»–é…ç½®
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'save_interval': 10,
        'log_interval': 5,
        'gradient_clip_value': 1.0
    }

    print("è®­ç»ƒé…ç½®:")
    for key, value in config.items():
        if key != 'loss_kwargs':
            print(f"  {key}: {value}")
    print()

    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = Path(config['data_dir'])
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("è¯·ç¡®ä¿å·²ç»è¿è¡Œäº†æ•°æ®å¤„ç†æ¨¡å—ç”Ÿæˆäº†HDF5æ•°æ®æ–‡ä»¶")
        return

    # åˆ—å‡ºå¯ç”¨çš„æ•°æ®æ–‡ä»¶
    h5_files = list(data_dir.glob("*.h5"))
    if not h5_files:
        print(f"âŒ åœ¨ {data_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°HDF5æ•°æ®æ–‡ä»¶")
        return

    print(f"âœ… æ‰¾åˆ° {len(h5_files)} ä¸ªHDF5æ•°æ®æ–‡ä»¶:")
    for file in h5_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  - {file.name}")
    if len(h5_files) > 5:
        print(f"  ... è¿˜æœ‰ {len(h5_files) - 5} ä¸ªæ–‡ä»¶")
    print()

    try:
        # åˆ›å»ºæ•°æ®æ¨¡å—
        print("ğŸ“Š åˆ›å»ºæ•°æ®æ¨¡å—...")
        data_module = CFDDataModule(
            data_dir=config['data_dir'],
            grid_size=config['grid_size'],
            batch_size=config['batch_size'],
            train_ratio=config['train_ratio'],
            val_ratio=config['val_ratio'],
            test_ratio=config['test_ratio'],
            normalize=True,
            velocity_scale=1.0
        )

        # è·å–æ•°æ®ä¿¡æ¯
        data_info = data_module.get_data_info()
        print(f"âœ… æ•°æ®æ¨¡å—åˆ›å»ºæˆåŠŸ:")
        print(f"  æ€»æ•°æ®æ–‡ä»¶: {data_info['total_files']}")
        print(f"  è®­ç»ƒé›†: {data_info['train_files']} æ–‡ä»¶")
        print(f"  éªŒè¯é›†: {data_info['val_files']} æ–‡ä»¶")
        print(f"  æµ‹è¯•é›†: {data_info['test_files']} æ–‡ä»¶")
        print(f"  ç½‘æ ¼å°ºå¯¸: {data_info['grid_size']}")
        print(f"  è¾“å…¥ç»´åº¦: {data_info['dataset_info']['input_dim']}")
        print(f"  è¾“å‡ºç»´åº¦: {data_info['dataset_info']['output_dim']}")
        print()

        # æ£€æŸ¥æ•°æ®é›†å¤§å°æ˜¯å¦è¶³å¤Ÿ
        if data_info['train_files'] < 2:
            print("âš ï¸  è­¦å‘Š: è®­ç»ƒæ•°æ®æ–‡ä»¶è¾ƒå°‘ï¼Œå»ºè®®ç”Ÿæˆæ›´å¤šè®­ç»ƒæ•°æ®")
            print("å¯ä»¥é€šè¿‡æ•°æ®å¤„ç†æ¨¡å—å¤„ç†å¤šä¸ªVTMæ–‡ä»¶æ¥ç”Ÿæˆæ›´å¤šHDF5æ•°æ®")
            print()

        # åˆ›å»ºè®­ç»ƒå™¨
        print("ğŸ§  åˆ›å»ºè®­ç»ƒå™¨...")
        trainer = create_trainer(
            model_type=config['model_type'],
            data_module=data_module,
            config=config
        )

        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in trainer.model.parameters())
        trainable_params = sum(p.numel() for p in trainer.model.parameters() if p.requires_grad)

        print(f"âœ… è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ:")
        print(f"  æ¨¡å‹ç±»å‹: {config['model_type']}")
        print(f"  æ€»å‚æ•°æ•°é‡: {total_params:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"  è®¾å¤‡: {trainer.device}")
        print()

        # å¼€å§‹è®­ç»ƒ
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print("=" * 50)

        # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
        models_dir = base_dir / 'models'
        models_dir.mkdir(exist_ok=True)

        # è®­ç»ƒæ¨¡å‹
        training_results = trainer.train(save_dir=str(models_dir))

        # è®­ç»ƒå®Œæˆ
        print("=" * 50)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"  æ€»è®­ç»ƒè½®æ•°: {training_results['total_epochs']}")
        print(f"  æœ€ä½³éªŒè¯æŸå¤±: {training_results['best_val_loss']:.6f}")
        print(f"  è®­ç»ƒè€—æ—¶: {training_results['training_time']/60:.2f} åˆ†é’Ÿ")
        print(f"  æ¨¡å‹ä¿å­˜åœ¨: {models_dir}")
        print()

        # å¦‚æœæœ‰æµ‹è¯•é›†ï¼Œè¿›è¡Œæœ€ç»ˆè¯„ä¼°
        if trainer.test_loader:
            print("ğŸ§ª è¿›è¡Œæœ€ç»ˆæµ‹è¯•è¯„ä¼°...")
            test_results = trainer.evaluate(trainer.test_loader)
            print("âœ… æµ‹è¯•ç»“æœ:")
            print(f"  æµ‹è¯•æŸå¤±: {test_results['total_loss']:.6f}")
            print(f"  æµ‹è¯•MAE: {test_results.get('mae_total', 0):.6f}")
            print(f"  æµ‹è¯•RMSE: {test_results.get('rmse_total', 0):.6f}")
            print(f"  æµ‹è¯•RÂ²: {test_results.get('r2_total', 0):.4f}")
            print(f"  è¾¹ç•Œè¿åç‡: {test_results.get('boundary_violation_ratio', 0):.4f}")
            print()

        # æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹
        print("ğŸ“ æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹:")
        print("```python")
        print("import torch")
        print("from neural_network import create_model")
        print()
        print("# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹")
        print("model = create_model('fc', grid_size=(64, 64, 64))")
        print(f"checkpoint = torch.load('{models_dir}/best_model.pth')")
        print("model.load_state_dict(checkpoint['model_state_dict'])")
        print("model.eval()")
        print()
        print("# è¿›è¡Œé¢„æµ‹")
        print("sdf_input = torch.randn(1, 262144)  # [batch_size, grid_points]")
        print("with torch.no_grad():")
        print("    velocity_pred = model(sdf_input)")
        print("    print(f'é¢„æµ‹é€Ÿåº¦åœºå½¢çŠ¶: {velocity_pred.shape}')")
        print("```")

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\nğŸ‰ ç¥ç»ç½‘ç»œè®­ç»ƒç¤ºä¾‹å®Œæˆ!")


def test_model_architecture():
    """æµ‹è¯•ä¸åŒçš„æ¨¡å‹æ¶æ„"""
    print("=== æµ‹è¯•æ¨¡å‹æ¶æ„ ===\n")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    grid_size = (64, 64, 64)
    grid_points = 64 * 64 * 64

    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = torch.randn(1, grid_points).to(device)

    model_configs = [
        ('fc', {'hidden_dims': [512, 1024, 2048, 1024, 512]}),
        ('conv', {'base_channels': 16, 'num_layers': 3}),
        ('hybrid', {'fc_dims': [512, 1024], 'conv_channels': 16})
    ]

    for model_type, model_kwargs in model_configs:
        try:
            print(f"æµ‹è¯• {model_type.upper()} æ¨¡å‹...")
            model = create_model(model_type, grid_size=grid_size, **model_kwargs).to(device)

            param_count = sum(p.numel() for p in model.parameters())
            print(f"  å‚æ•°æ•°é‡: {param_count:,}")

            with torch.no_grad():
                output = model(test_input)
                print(f"  è¾“å…¥å½¢çŠ¶: {test_input.shape}")
                print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
                print(f"  âœ… {model_type.upper()} æ¨¡å‹æµ‹è¯•æˆåŠŸ")

        except Exception as e:
            print(f"  âŒ {model_type.upper()} æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        print()


if __name__ == "__main__":
    # è®¾ç½®è­¦å‘Šçº§åˆ«
    warnings.filterwarnings("ignore", category=UserWarning)

    # å¯ä»¥é€‰æ‹©æµ‹è¯•æ¨¡å‹æ¶æ„æˆ–ç›´æ¥è®­ç»ƒ
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == 'test':
        # æµ‹è¯•æ¨¡å‹æ¶æ„
        test_model_architecture()
    else:
        # è¿è¡Œè®­ç»ƒç¤ºä¾‹
        main()